{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Word Frequency Calculation\n",
    "\n",
    "##### Please refer to the Python Requirements and Installation Guide pdf \n",
    "\n",
    "The function of this notebook is to calculate the frequencies of words that appear in each column that contains plain text in the Kununu reviews dataframe. This process is done for each company and for each year where reviews are written. The desired output is a JSON file which contains word frequency information per column, per year, and per company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jupyter-\n",
      "[nltk_data]     vinh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read & Concat CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_concat(path_to_csv_files: str):\n",
    "    \"\"\"\n",
    "    This function reads in, concatenates, and prepares the translated csv files of each company's Kununu reviews.\n",
    "        \n",
    "    :param path_to_csv_files: path to folder containing the translated csv files\n",
    "\n",
    "    :return: single dataframe which contains all the observations and features of each company's Kununu reviews              \n",
    "    \"\"\"\n",
    "    csv_files = os.listdir(path_to_csv_files)\n",
    "    df_list = []\n",
    "    for i in csv_files:\n",
    "        name = i.replace('_translated.csv', '')\n",
    "        df = pd.read_csv(f'{path_to_csv_files}/{i}', sep = '\\t')\n",
    "        df = df.drop('Unnamed: 0', axis = 1)\n",
    "        df.insert(0, 'company', [name] * df.shape[0])\n",
    "        \n",
    "        # Date separation (add separate `year` and `month` column)\n",
    "        df.loc[:, 'review_date'] = pd.to_datetime(df.loc[:, 'review_date'])\n",
    "        df.sort_values('review_date', ascending = False)\n",
    "        df.insert(1, 'year', df['review_date'].dt.year)\n",
    "        df.insert(2, 'month', df['review_date'].dt.month)\n",
    "        df.pop('review_date')\n",
    "        \n",
    "        df_list.append(df)\n",
    "        \n",
    "    # Concatenating all the dataframes\n",
    "    concat_df = pd.concat(df_list, axis = 0, ignore_index = True)\n",
    "    \n",
    "    return concat_df\n",
    "\n",
    "# ---- Example code ----\n",
    "# Make sure to not have a '/' character at the very end of the path. Please provide your own path to the folder of translated csv files.\n",
    "# The files are read from the \"translated_csvs_folder\" folder'directory\n",
    "df = read_and_concat('/home/jupyter-vinh/strategy/final_project/translated_csvs_folder')\n",
    "# df.to_csv('/home/jupyter-vinh/concat_df.csv', index = False, header = True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_freq_yearly(df, *column_names):\n",
    "    '''\n",
    "    This function calculates the word frequency of text columns in a single dataframe.\n",
    "    \n",
    "    :param df: dataframe of company with which you would like to calculate the word frequency\n",
    "    :param *column_names: arg variable which accepts a list of column names indicating which columns word frequency \n",
    "                          should be calculated\n",
    "                          \n",
    "    :return: a nested dictionary which supplies word frequency information hierarchically by year, column name, word, and frequency\n",
    "    '''\n",
    "    years = df['year'].unique()\n",
    "\n",
    "    word_freq_per_year_and_col = dict()\n",
    "    for c_name in column_names:\n",
    "        \n",
    "        word_freq_per_year = dict()\n",
    "        for year in years:\n",
    "            filtered_df = df.loc[df['year'] == year] # filter df by year\n",
    "            filtered_df = filtered_df.loc[filtered_df[c_name].notnull()] # remove nan from column\n",
    "            text_tokens = filtered_df[c_name].str.lower().str.split() # split text in each row into a list of tokens\n",
    "            text_tokens = [i for i in text_tokens if i != []] # remove empty lists\n",
    "            text_tokens = [[''.join(e for e in string if e.isalnum()) for string in lst] for lst in text_tokens] # remove punctuation, spaces, parentheses, etc.\n",
    "            text_tokens = [[word for word in lst if not word in stopwords.words('english')] for lst in text_tokens] # remove stopwords\n",
    "            all_words = [str(i) for lst in text_tokens for i in lst] # creates a single list of all the words in text_tokens\n",
    "            all_words = [i for i in all_words if i] # remove empty strings\n",
    "            \n",
    "            dct = dict()\n",
    "            for i in all_words:\n",
    "                dct[i] = dct.get(i, 0) + 1\n",
    "                \n",
    "            word_freq_per_year[f'{year}'] = dct\n",
    "    \n",
    "        word_freq_per_year_and_col[c_name] = word_freq_per_year\n",
    "    \n",
    "    return word_freq_per_year_and_col\n",
    "\n",
    "def company_bow(df):\n",
    "    '''\n",
    "    This function calculates the word frequency per company, per year, and per column using extract_word_freq_yearly as a helper\n",
    "    function.\n",
    "    \n",
    "    :param df: a dataframe that contains the Kununu reviews of all the companies where you would like to calculate word frequency\n",
    "    \n",
    "    :return: a nested dictionary which supplies word frequency information hierarchically by company, year, column name, word, and frequency\n",
    "    '''\n",
    "    companies = df['company'].unique()\n",
    "    all_bow = dict()\n",
    "    for company in companies:\n",
    "        filtered_df = df.loc[df['company'] == company]\n",
    "        cols = list(filtered_df.filter(like = 'plain_text', axis = 1).columns)\n",
    "        all_bow[company] = extract_word_freq_yearly(filtered_df, *cols)\n",
    "    \n",
    "    return all_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_bow = company_bow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to store final word frequency dictionary as a json file.\n",
    "# \"company_bow.json\" is found in the main directory - \"Strategy Final Project\"\n",
    "# with open('/home/jupyter-vinh/company_bow.json', 'w') as f:\n",
    "#     json.dump(company_bow, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Topic Modeling & Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please provide your own path to the word dictionary.\n",
    "# The word dictionary dervied through topic modelling can be found in 'Strategy Final Project'\n",
    "gut_am_arbeitgeber = pd.read_excel('/home/jupyter-vinh/strategy/final_project/word_dictionary_final.xlsx', sheet_name = 'Sheet1', skiprows = 2)\n",
    "schlecht_am_arbeitgeber = pd.read_excel('/home/jupyter-vinh/strategy/final_project/word_dictionary_final.xlsx', sheet_name = 'Sheet2', skiprows = 2)\n",
    "\n",
    "def create_word_lists(df):\n",
    "    '''\n",
    "    This function creates a dictionary of words per topic given a dataframe.\n",
    "    \n",
    "    :param df: dataframe which contains dictionary of words which makes up different topics with a Kununu text review column\n",
    "    \n",
    "    :return: a dictionary where the key is a topic and the value is a list of words within that topic\n",
    "    '''\n",
    "    car_opp = list(df.loc[df['Topic 1: Career Opportunities'].notnull()]['Topic 1: Career Opportunities'])\n",
    "    car_opp = [word.lower() for word in car_opp]\n",
    "    \n",
    "    remuneration = list(df.loc[df['Topic 2: Remuneration'].notnull()]['Topic 2: Remuneration'])\n",
    "    remuneration = [word.lower() for word in remuneration]\n",
    "    \n",
    "    team_dyn = list(df.loc[df['Topic 3: Team Dynamic'].notnull()]['Topic 3: Team Dynamic'])\n",
    "    team_dym = [word.lower() for word in team_dyn]\n",
    "    \n",
    "    return {'Career Opportunities': car_opp,\n",
    "            'Remuneration': remuneration, \n",
    "            'Team Dynamic': team_dyn}\n",
    "    \n",
    "gut_topics_word_freq = create_word_lists(gut_am_arbeitgeber)\n",
    "schlecht_topics_word_freq = create_word_lists(schlecht_am_arbeitgeber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series_df(master_dict: dict, \n",
    "                          company_name: str, \n",
    "                          gut_topics: dict,\n",
    "                          schlect_topics: dict):\n",
    "    '''\n",
    "    This function creates a dataframe which can then be used for time series analysis.\n",
    "    \n",
    "    :param master_dict: dictionary containing all word frequency information for each company\n",
    "    :param company_name: name of company where you would like to perform time series analysis\n",
    "    :param gut_topics: list of words for each topic in column `Gut am Arbeitgeber finde ich_plain_text`\n",
    "    :param schlecht_topics: list of words for each topic in column `Gut am Arbeitgeber finde ich_plain_text`\n",
    "    \n",
    "    :return: A dataframe with four columns, topic, word_count, year, and feature. The word count column is a percentage\n",
    "             indicating the percentage of words that appeared in a topic amongst all words in the feature (Kununu review column).\n",
    "    '''\n",
    "    \n",
    "    df1_list = []\n",
    "    years = master_dict[company_name]['Gut am Arbeitgeber finde ich_plain_text'].keys()\n",
    "    for key, value in gut_topics.items():\n",
    "        for year in years:\n",
    "            word_count_single_year = master_dict[company_name]['Gut am Arbeitgeber finde ich_plain_text'][year]\n",
    "            topic_word_count = dict.fromkeys(value, 0)\n",
    "            for k in topic_word_count.keys():\n",
    "                if k in word_count_single_year:\n",
    "                    topic_word_count[k] = word_count_single_year[k]\n",
    "            \n",
    "            single_year = {'topic': [key],\n",
    "                           'word_count': [sum(topic_word_count.values())],\n",
    "                           'year': [int(year)],\n",
    "                           'feature': ['Gut am Arbeitgeber finde ich_plain_text'.replace(' finde ich_plain_text', '')]\n",
    "            }\n",
    "            single_year_df = pd.DataFrame(single_year)\n",
    "            df1_list.append(single_year_df)\n",
    "    df1 = pd.concat(df1_list)\n",
    "    \n",
    "    df2_list = []\n",
    "    years = master_dict[company_name]['Schlecht am Arbeitgeber finde ich_plain_text'].keys()\n",
    "    for key, value in schlect_topics.items():\n",
    "        for year in years:\n",
    "            word_count_single_year = master_dict[company_name]['Schlecht am Arbeitgeber finde ich_plain_text'][year]\n",
    "            topic_word_count = dict.fromkeys(value, 0)\n",
    "            for k in topic_word_count.keys():\n",
    "                if k in word_count_single_year:\n",
    "                    topic_word_count[k] = word_count_single_year[k]\n",
    "            \n",
    "            single_year = {'topic': [key],\n",
    "                           'word_count': [sum(topic_word_count.values())],\n",
    "                           'year': [int(year)],\n",
    "                           'feature': ['Schlecht am Arbeitgeber finde ich_plain_text'.replace(' finde ich_plain_text', '')]\n",
    "            }\n",
    "            single_year_df = pd.DataFrame(single_year)\n",
    "            df2_list.append(single_year_df)\n",
    "    df2 = pd.concat(df2_list)\n",
    "    \n",
    "    return pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bechtle_visualization = create_time_series_df(company_bow, 'bechtle', gut_topics_word_freq, schlecht_topics_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = bechtle_visualization.year.unique()\n",
    "for year in years:\n",
    "    word_year_sum_gut = sum(company_bow['bechtle']['Gut am Arbeitgeber finde ich_plain_text'][str(year)].values())\n",
    "    word_year_sum_schlecht = sum(company_bow['bechtle']['Schlecht am Arbeitgeber finde ich_plain_text'][str(year)].values())\n",
    "    \n",
    "    bechtle_visualization['word_count'] = np.where((bechtle_visualization.year == year) & (bechtle_visualization.feature == 'Gut am Arbeitgeber'),\n",
    "                                                    bechtle_visualization.word_count / word_year_sum_gut,\n",
    "                                                    bechtle_visualization.word_count)\n",
    "    bechtle_visualization['word_count'] = np.where((bechtle_visualization.year == year) & (bechtle_visualization.feature == 'Schlecht am Arbeitgeber'),\n",
    "                                                    bechtle_visualization.word_count / word_year_sum_schlecht,\n",
    "                                                    bechtle_visualization.word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bechtle_visualization.to_csv('/home/jupyter-vinh/strategy/final_project/bechtle_visualization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sap_visualization = create_time_series_df(company_bow, 'sap', gut_topics_word_freq, schlecht_topics_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = sap_visualization.year.unique()\n",
    "for year in years:\n",
    "    word_year_sum_gut = sum(company_bow['sap']['Gut am Arbeitgeber finde ich_plain_text'][str(year)].values())\n",
    "    word_year_sum_schlecht = sum(company_bow['sap']['Schlecht am Arbeitgeber finde ich_plain_text'][str(year)].values())\n",
    "    \n",
    "    sap_visualization['word_count'] = np.where((sap_visualization.year == year) & (sap_visualization.feature == 'Gut am Arbeitgeber'),\n",
    "                                                sap_visualization.word_count / word_year_sum_gut,\n",
    "                                                sap_visualization.word_count)\n",
    "    sap_visualization['word_count'] = np.where((sap_visualization.year == year) & (sap_visualization.feature == 'Schlecht am Arbeitgeber'),\n",
    "                                                sap_visualization.word_count / word_year_sum_schlecht,\n",
    "                                                sap_visualization.word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sap_visualization.to_csv('/home/jupyter-vinh/strategy/final_project/sap_visualization.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_cloud_df(master_dict: dict,\n",
    "                        company_name: str,\n",
    "                        gut_topics: dict,\n",
    "                        schlecht_topics: dict,\n",
    "                        years: list):\n",
    "    '''\n",
    "    This function creates a dataframe which can then be used to create a word cloud.\n",
    "    \n",
    "    :param master_dict: dictionary containing all word frequency information for each company\n",
    "    :param company_name: name of company where you would like to perform time series analysis\n",
    "    :param gut_topics: list of words for each topic in column `Gut am Arbeitgeber finde ich_plain_text`\n",
    "    :param schlecht_topics: list of words for each topic in column `Gut am Arbeitgeber finde ich_plain_text`\n",
    "    :param years: a list which indicates which years you would like to look at to create the word cloud\n",
    "    \n",
    "    :return: A dataframe with three columns, feature, topic, text. The feature column indicates the Kununu review column. The topic column\n",
    "             indicates the topic in the review column. The text column aggregates all the words in that topic in that column for the years specified.\n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['feature', 'topic', 'text'])\n",
    "    \n",
    "    for key, value in gut_topics.items():\n",
    "        topic_word_count = dict.fromkeys(value, 0)\n",
    "        for year in years:\n",
    "            word_count_single_year = master_dict[company_name]['Gut am Arbeitgeber finde ich_plain_text'][year]\n",
    "            for k in topic_word_count.keys():\n",
    "                if k in word_count_single_year:\n",
    "                    topic_word_count[k] += word_count_single_year[k]\n",
    "        \n",
    "        string = ''\n",
    "        for _key, _value in topic_word_count.items():\n",
    "            key_expand = ' '.join([_key] * _value) + ' '\n",
    "            string += key_expand      \n",
    "        \n",
    "        row = pd.DataFrame({'feature': ['Gut am Arbeitgeber'],\n",
    "                            'topic': [key],\n",
    "                            'text': [string]})\n",
    "        df = pd.concat([df, row])\n",
    "    \n",
    "    for key, value in schlecht_topics.items():\n",
    "        topic_word_count = dict.fromkeys(value, 0)\n",
    "        for year in years:\n",
    "            word_count_single_year = master_dict[company_name]['Schlecht am Arbeitgeber finde ich_plain_text'][year]\n",
    "            for k in topic_word_count.keys():\n",
    "                if k in word_count_single_year:\n",
    "                    topic_word_count[k] += word_count_single_year[k]\n",
    "        \n",
    "        string = ''\n",
    "        for _key, _value in topic_word_count.items():\n",
    "            key_expand = ' '.join([_key] * _value) + ' '\n",
    "            string += key_expand      \n",
    "        \n",
    "        row = pd.DataFrame({'feature': ['Schlecht am Arbeitgeber'],\n",
    "                            'topic': [key],\n",
    "                            'text': [string]})\n",
    "        df = pd.concat([df, row])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bechtle_wordcloud = create_word_cloud_df(company_bow, 'bechtle', gut_topics = gut_topics_word_freq, schlecht_topics = schlecht_topics_word_freq, years = ['2020', '2021', '2022'])\n",
    "# bechtle_wordcloud.to_csv('/home/jupyter-vinh/strategy/final_project/bechtle_wordcloud.csv')\n",
    "sap_wordcloud = create_word_cloud_df(company_bow, 'sap', gut_topics = gut_topics_word_freq, schlecht_topics = schlecht_topics_word_freq, years = ['2020', '2021', '2022'])\n",
    "# sap_wordcloud.to_csv('/home/jupyter-vinh/strategy/final_project/sap_wordcloud.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proportion Comparison\n",
    "\n",
    "Please do not run this code, this is just data analysis work using the dataframe generated from the create_word_cloud_df function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bechtle_proportion = pd.read_csv('/home/jupyter-vinh/strategy/final_project/bechtle_visualization.csv')\n",
    "# bechtle_proportion = bechtle_proportion.drop(['Unnamed: 0'], axis = 1)\n",
    "# bechtle_proportion = bechtle_proportion.loc[bechtle_proportion['year'].isin([2020, 2021, 2022])]\n",
    "\n",
    "# sap_proportion = pd.read_csv('/home/jupyter-vinh/strategy/final_project/sap_visualization.csv')\n",
    "# sap_proportion = sap_proportion.drop(['Unnamed: 0'], axis = 1)\n",
    "# sap_proportion = sap_proportion.loc[sap_proportion['year'].isin([2020, 2021, 2022])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>topic</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gut am Arbeitgeber</td>\n",
       "      <td>Management</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gut am Arbeitgeber</td>\n",
       "      <td>Remuneration</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gut am Arbeitgeber</td>\n",
       "      <td>Work Environment</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schlecht am Arbeitgeber</td>\n",
       "      <td>Management</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schlecht am Arbeitgeber</td>\n",
       "      <td>Remuneration</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schlecht am Arbeitgeber</td>\n",
       "      <td>Work Environment</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature             topic  word_count\n",
       "0       Gut am Arbeitgeber        Management         306\n",
       "1       Gut am Arbeitgeber      Remuneration          75\n",
       "2       Gut am Arbeitgeber  Work Environment         308\n",
       "3  Schlecht am Arbeitgeber        Management         128\n",
       "4  Schlecht am Arbeitgeber      Remuneration          77\n",
       "5  Schlecht am Arbeitgeber  Work Environment         113"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bechtle_grouped = bechtle_proportion.groupby(['feature', 'topic'])[['word_count']].sum().reset_index()\n",
    "# bechtle_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>topic</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gut am Arbeitgeber</td>\n",
       "      <td>Management</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gut am Arbeitgeber</td>\n",
       "      <td>Remuneration</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gut am Arbeitgeber</td>\n",
       "      <td>Work Environment</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schlecht am Arbeitgeber</td>\n",
       "      <td>Management</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schlecht am Arbeitgeber</td>\n",
       "      <td>Remuneration</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schlecht am Arbeitgeber</td>\n",
       "      <td>Work Environment</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature             topic  word_count\n",
       "0       Gut am Arbeitgeber        Management         853\n",
       "1       Gut am Arbeitgeber      Remuneration         275\n",
       "2       Gut am Arbeitgeber  Work Environment        1003\n",
       "3  Schlecht am Arbeitgeber        Management         133\n",
       "4  Schlecht am Arbeitgeber      Remuneration          51\n",
       "5  Schlecht am Arbeitgeber  Work Environment          82"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sap_grouped = sap_proportion.groupby(['feature', 'topic'])[['word_count']].sum().reset_index()\n",
    "# sap_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "#### End of Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "870cd4e981f2acadc7fc93f1432c29ad0039f04ea86b6d6b40354c4c09082a3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
